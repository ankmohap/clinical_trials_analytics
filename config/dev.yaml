# Development environment configuration for Clinical Trials ETL

# AWS Configuration
aws:
  region: us-east-1
  s3_bucket_name: clinical-trials-data-dev

# Snowflake Configuration
snowflake:
  account: ${SNOWFLAKE_ACCOUNT}
  user: ${SNOWFLAKE_USER}
  password: ${SNOWFLAKE_PASSWORD}
  warehouse: COMPUTE_WH
  database: CLINICAL_TRIALS_DEV
  schema: RAW_DATA

# Clinical Trial API Configuration
clinical_trial_api:
  base_url: https://clinicaltrials.gov/api/query
  api_key: ${CLINICAL_TRIAL_API_KEY}
  rate_limit_per_second: 10
  max_studies_per_batch: 1000
  days_lookback: 7

# Data Processing Configuration
data_processing:
  batch_size: 1000
  file_format: parquet
  compression: snappy
  max_file_size_mb: 100

# Airflow Configuration
airflow:
  dag_id: clinical_trials_etl_dev
  schedule_interval: "0 7 * * 1"  # Every Monday at 7 AM
  max_active_runs: 1
  catchup: false
  email_on_failure: true
  email_on_retry: false
  retries: 2
  retry_delay_minutes: 5

# Monitoring and Alerting
monitoring:
  email_notifications: true
  slack_notifications: false
  data_quality_checks: true
  performance_metrics: true

# Logging Configuration
logging:
  level: INFO
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file_rotation: daily
  retention_days: 30

# Data Quality Thresholds
data_quality:
  min_records_per_batch: 1
  max_null_percentage: 5
  max_duplicate_percentage: 1
  required_fields:
    - nct_id
    - brief_title
    - overall_status
    - study_type